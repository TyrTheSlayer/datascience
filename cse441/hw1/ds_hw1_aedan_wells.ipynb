{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Datascience Homework 1##\n",
        "Author: Aedan Wells\n",
        "\n",
        "Date: 9/19/22\n",
        "\n",
        "Brief: Program for a user to analyze specific protions of a large text file. The text file will be too large to just hold in memory, so it will be good to have a software that can process this well. Analysis includes word queries that yield if a word is in the specified paragraphs and where and paragraph queries that return the number of words in the paragraph, the first and last word in the paragraph as well as a random word.\n",
        "\n",
        "This note book accomplishes everything the homework specifies including requested functions, word/paragraph queries, only parsing the text once, user prompt, and dealing with illegal entries.  \n",
        "\n",
        "Notes:\n",
        "*   When running this code, if you keyboard interrupt instead of ending the program with the termination command, please rerun the first cell of the playbook. Otherwise, the global DICTIONARY will still hold the previous dictionary and create strange output. If ran in a normal python file, this issue would not come up.\n",
        "*   I solved the exponential number problem as posited in section 1 with numbers (123.45, and 1.2345E02 are equivalent to 123.45). However, after seeing textfile2, I did not implement latex style numeric changes (e.g. 5\\times10^{-4}). I wanted to acknowledge the problems given to us but not deal with every possible numerical representation as that would be impossible. \n",
        "\n"
      ],
      "metadata": {
        "id": "eyR5xbvSxShH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import random and set global basic dictionary\n",
        "import random as rand\n",
        "DICTIONARY = {}"
      ],
      "metadata": {
        "id": "_TjKO2Y5xIM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up the word to make it common for application\n",
        "#param word is the word being cleaned\n",
        "#returns cleaned word\n",
        "def clean_word(word):\n",
        "  num = 0\n",
        "  exp = 1\n",
        "  #make the word lowercase\n",
        "  word = word.lower()\n",
        "  #if the string has a number, clean it like a number\n",
        "  if True in [char.isdigit() for char in word]:\n",
        "    #if needs exponential, multiply LHS by 10^RHS\n",
        "    if 'e0' in word:\n",
        "      splitted = word.split('e0')\n",
        "      for i in range(int(splitted[1])):\n",
        "        exp = exp * 10\n",
        "      splitted[0] = splitted[0].strip(\",$#?!<>\\]\\[\\:\\/\\;()\\\"*&\\^\\%@\")\n",
        "      num = float(splitted[0]) * exp\n",
        "      num = round(num, len(splitted[0]))\n",
        "      return str(num)\n",
        "    #if last character is a period, remove it. This allows decimals to exist without ending punctuation\n",
        "    last_char = word[len(word) - 1]\n",
        "    if last_char == \".\":\n",
        "      word = word[:-1]\n",
        "    word = word.strip(\",$#?!<>\\]\\[\\:\\/\\;()\\\"*&\\^\\%@\")\n",
        "  else:\n",
        "    word = word.strip(\",.$#?!<>\\]\\[\\:\\/\\;()\\\"*&\\^\\%@\")\n",
        "  return word"
      ],
      "metadata": {
        "id": "skRIqwo22pVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHzI_neWwJJY"
      },
      "outputs": [],
      "source": [
        "#generator function designed to return the content of the next paragraph from the file specified in its input.\n",
        "#param filename is the name of the file being iterated on\n",
        "#yields the paragraoh if paragraphs remain, \n",
        "def gen_read_para(filename):\n",
        "  #read the file\n",
        "  try:\n",
        "    f = open(filename, 'r')\n",
        "  except FileNotFoundError as missing_file_err:\n",
        "    print(f'File is missing: *** {missing_file_err}***')\n",
        "    exit(0)\n",
        "  \n",
        "  para = []\n",
        "  while True:\n",
        "    line = f.readline()\n",
        "    #if EOF or just a new line\n",
        "    if (line == '\\n') or (line == ''):\n",
        "      #if para has content, return that\n",
        "      if para != []:\n",
        "        yield(para)\n",
        "        para = []\n",
        "      # if EOF, return None\n",
        "      if line == '':\n",
        "        f.close()\n",
        "        return None\n",
        "    else:\n",
        "      #grab the line, split the words and add to the list\n",
        "      tmp = line.split()\n",
        "      for i in range(len(tmp)):\n",
        "        para.append(clean_word(tmp[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#will return a list of words in the specified paragraph in their order of appearance\n",
        "#param para_stream is the iterator from gen_read_para() function\n",
        "#param para_num is the paragraph number we want the list of words from\n",
        "#param prev_para_num last paragraph number to get the appropriate paragraph from the generator (no rereading)\n",
        "#returns word_list, the list of words in the paragraph. Returns None if StopIteration is triggered\n",
        "def get_words_in_para(para_stream, para_num, prev_para_num):\n",
        "  try:\n",
        "    word_list = []\n",
        "    #range of current number - previous paragraph num, that yields how many to go forward\n",
        "    for i in range(para_num - prev_para_num):\n",
        "      word_list = next(para_stream)\n",
        "    return word_list\n",
        "  except StopIteration:\n",
        "    return None"
      ],
      "metadata": {
        "id": "ZrfFptZpzSnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#return all the words in all the paragraphs in the input list\n",
        "#param para_stream is the iterator from gen_read_para() function\n",
        "#param para_num_list is the list of paragraph numbers being analyzed\n",
        "#returns para_dict, a dictionary of each paragraph pointing to a list of the words in the paragraph in order\n",
        "def get_words_in_all_paras(para_stream, para_num_list):\n",
        "  para_dict = {}\n",
        "  last_para = -1\n",
        "  #for each paragraph, get the words\n",
        "  for para in para_num_list:\n",
        "    tmp = get_words_in_para(para_stream, para, last_para)\n",
        "    #check here in case get_words returns None\n",
        "    if tmp is not None:\n",
        "      para_dict[para] = tmp\n",
        "    last_para = para\n",
        "  return para_dict"
      ],
      "metadata": {
        "id": "GEdpIOTizqCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates a global dictionary DICTIONARY in which every word w in the paragraphs \n",
        "#exist pointing to what paragraph they are in and where\n",
        "#param para_stream is the iterator from gen_read_para() function\n",
        "#param para_num_list is the list of paragraph numbers being analyzed\n",
        "#returns paragraph_dict which is a dictionary of paragraph number pointing to the text in the paragraph\n",
        "def analyze_paras(para_stream, para_num_list):\n",
        "  global DICTIONARY\n",
        "  paragraph_dict = get_words_in_all_paras(para_stream, para_num_list)\n",
        "  #for each paragraph \n",
        "  for paragraph in paragraph_dict.keys():\n",
        "    word_list = paragraph_dict[paragraph]\n",
        "    word_offset = 0\n",
        "    #for each word in the paragraph\n",
        "    for word_new in word_list:\n",
        "      #if the word is in the dictionary\n",
        "      if word_new in DICTIONARY.keys():\n",
        "        #if the paragraph is recorded for the word\n",
        "        if paragraph in DICTIONARY[word_new].keys():\n",
        "          #append the word offset for this paragraph\n",
        "          DICTIONARY[word_new][paragraph].append(word_offset)\n",
        "        #else if it does not have this paragraph, put that in and the offset  \n",
        "        else:\n",
        "          DICTIONARY[word_new].update({paragraph : []})\n",
        "          DICTIONARY[word_new][paragraph].append(word_offset)\n",
        "      #else if there is no word recorded, put it in plus the paragraph number\n",
        "      else:\n",
        "        DICTIONARY[word_new] = {paragraph : []}\n",
        "        DICTIONARY[word_new][paragraph].append(word_offset)\n",
        "      word_offset += 1\n",
        "  return paragraph_dict"
      ],
      "metadata": {
        "id": "KJRFmwKw06Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performs the $ w word query. Print what paragraphs they are in and where if it is in the document\n",
        "#param word is the word being queried\n",
        "#param word_query_count is the dictionary that holds how much a word is searched\n",
        "def word_query(word, word_query_count):\n",
        "  global DICTIONARY\n",
        "  #if word is not in the word_query_count list, add it\n",
        "  if word not in word_query_count.keys():\n",
        "      word_query_count[word] = 0\n",
        "  #find how much word has been queried and print the val\n",
        "  word_query_count[word] += 1\n",
        "  print(\"Word has been queried \" + str(word_query_count[word]) + \" times\")\n",
        "\n",
        "  #if word is not in dict keys, print not found and exit\n",
        "  if word not in DICTIONARY.keys():\n",
        "    print(\"Word not found\")\n",
        "    print(\"\\n\")\n",
        "    return\n",
        "  else:\n",
        "    print(\"The word has been found! \" + word + \" was found in the following paragraphs and offsets:\")\n",
        "    for para in DICTIONARY[word]:\n",
        "      for offset in DICTIONARY[word][para]:\n",
        "        print(\"Paragraph \" + str(para) + \" at offset \" + str(offset))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "ogzx3ITW2xYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performs the # j paragraph query. Print the first, last, and random word in the paragraph with \n",
        "#param para_num is the paragraph number performed by the query\n",
        "#param para_num_list is the list of paragraph numbers\n",
        "def para_query(para_num, para_num_list, paragraph_dict):\n",
        "  #If paranum but from preprocessed list\n",
        "  if (int(para_num) not in para_num_list) or (int(para_num) not in paragraph_dict.keys()):\n",
        "    print(\"Paragraph not in provided list\")\n",
        "    print(\"\\n\")\n",
        "    return\n",
        "\n",
        "  word_list = paragraph_dict[int(para_num)]\n",
        "  #gets random word value from wordlist value\n",
        "  r = rand.randint(1, len(word_list) - 2)\n",
        "  first_word = word_list[0]\n",
        "  last_word = word_list[len(word_list) - 1]\n",
        "  random_word = word_list[r]\n",
        "  print(str(len(word_list)) + \", 1: '\" + first_word + \"', \" + str(len(word_list)) + \": '\" + last_word + \"',  \" + str(r) + \": '\" + random_word + \"'\\n\")"
      ],
      "metadata": {
        "id": "P64fIkda8OZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creates the word_query_count dictionary for each word\n",
        "#returns word_query_count dictionary all initiated to 0\n",
        "def init_word_query_count():\n",
        "  global DICTIONARY\n",
        "  keys = DICTIONARY.keys()\n",
        "  word_query_count = {}\n",
        "  for item in keys:\n",
        "    word_query_count[item] = 0\n",
        "  return word_query_count"
      ],
      "metadata": {
        "id": "XJZxOF0045G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#will initiate the analysis and fill the global dictionary / dictionaries.\n",
        "#param file_name is the file name\n",
        "#param para_num_list is the list of paragraph numbers being analyzed\n",
        "def analyze(file_name, para_num_list):\n",
        "  global DICTIONARY\n",
        "  #grab para stream\n",
        "  para_stream = gen_read_para(file_name)\n",
        "  #create global dictionary\n",
        "  paragraph_dict = analyze_paras(para_stream, para_num_list)\n",
        "  word_query_count = init_word_query_count()\n",
        "  #grab what the user wants to compute\n",
        "  entry = input('Enter analysis sequence: ')\n",
        "  while entry != '/':\n",
        "    tmp = entry.split()\n",
        "\n",
        "    #do a word query\n",
        "    if tmp[0] == '$':\n",
        "      word_query(tmp[1], word_query_count)\n",
        "    #do a paragraph query\n",
        "    elif tmp[0] == '#':\n",
        "      if tmp[1].isdigit():\n",
        "        para_query(tmp[1], para_num_list, paragraph_dict)\n",
        "      else:\n",
        "        print(\"Paragraph needs to be given in number term\")\n",
        "    else:\n",
        "      print(\"Improper input\")\n",
        "\n",
        "    #cleanup for next data entry\n",
        "    tmp.clear()\n",
        "    entry = input('Enter analysis sequence: ')\n",
        "  DICTIONARY = {}"
      ],
      "metadata": {
        "id": "k4bzqKyE09oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleans up the paragraph number list. Sorts it, removes duplicates\n",
        "#param para_num_list is user given list\n",
        "#returns a cleaned up para_num_list\n",
        "def clean_para_list(para_num_list):\n",
        "  #make a dict from keys then put back into lists\n",
        "  de_dup = list(dict.fromkeys(para_num_list))\n",
        "  #sort it\n",
        "  de_dup.sort()\n",
        "  return de_dup"
      ],
      "metadata": {
        "id": "voKOq657YJ5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  para_num_list = []\n",
        "  filename = input('Enter the filename to be analyzed: ')\n",
        "  \n",
        "  #while the last line is not empty, keep getting paragraph numbers\n",
        "  entry = input('Enter paragraph numbers: ')\n",
        "  while entry != '':\n",
        "    tmp = entry.split()\n",
        "    for i in range(len(tmp)):\n",
        "      if tmp[i].isdigit():\n",
        "        para_num_list.append(int(tmp[i]))\n",
        "    entry = input('Enter paragraph numbers:')\n",
        "  \n",
        "  #clean up the paragraph list\n",
        "  para_num_list = clean_para_list(para_num_list)\n",
        "  #analyze\n",
        "  analyze(filename, para_num_list)\n",
        "  print(\"Terminated\")"
      ],
      "metadata": {
        "id": "ky4iuRoT2FNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMGj-cyiqJWw",
        "outputId": "bf33526b-27f4-4ea8-8e91-29413ec609ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the filename to be analyzed: textfile2.txt\n",
            "Enter paragraph numbers: 1\n",
            "Enter paragraph numbers:\n",
            "Enter analysis sequence: $ this\n",
            "Word has been queried 1 times\n",
            "The word has been found! this was found in the following paragraphs and offsets:\n",
            "Paragraph 1 at offset 7\n",
            "Paragraph 1 at offset 36\n",
            "\n",
            "\n",
            "Enter analysis sequence: /\n",
            "Terminated\n"
          ]
        }
      ]
    }
  ]
}