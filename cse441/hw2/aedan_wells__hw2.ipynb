{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Datascience Homework 2##\n",
        "Author: Aedan Wells\n",
        "\n",
        "Date: 10/03/22\n",
        "\n",
        "Brief: Program for a user to output and interpret grade information for multiple assignments and rules. This includes applying weights for overall grades, dropping low grades when appropriate, and outputting statistical information.\n",
        "\n",
        "This entry completes all portions asked:\n",
        "\n",
        "\n",
        "*   Prints table 1 with adjustable columns to make sure all data fits\n",
        "*   Prints table 2 using raw values of student grades as data source for it was not specified\n",
        "*   Prints table 3 using the pearson coefficient values\n",
        "*   Utilizes only the numpy library when possible and python provided functions\n",
        "*   All section specifics such as csv name stored as a constant and no crashes was considered\n",
        "*   Completed extra credit, added drop directive and printing table 4 in a clean manner\n",
        "\n",
        "Notes:\n",
        "* Extra credit was completed but it is currently commented out so you can see how the code performs without it. I am not confident that the values after dropping are right so it is commented out\n",
        "* To see the drop directive and Table 4 for the extra credit, uncomment the lines beneath the comments \"UNCOMMENT THE BELOW FOR EC PORTION\" within the main function. These should be the calls 'data, table4 = drop_directive(data, about_data)' and 'print_table4(table4)'\n",
        "\n"
      ],
      "metadata": {
        "id": "77f5vU5JEJnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vGZ0a71OFerk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splits the about data into individual arrays for easier parsing\n",
        "#param about_data is the about_data array given from the CSV\n",
        "#returns each row separated with the first label removed\n",
        "def split_data(about_data):                                                         \n",
        "  assert (about_data[0,0], about_data[1,0], about_data[2,0], about_data[3,0]) ==  ('HEADERS',\n",
        "                         'WEIGHTS', 'OUTOF', 'GROUP'), '***Input file ERROR in Row headers'\n",
        "  names = about_data[0, 1:]\n",
        "  about = about_data[1:4, 1:]  # keep only the numeric part                                   \n",
        "  # convert each empty string to nan                                                    \n",
        "  with np.nditer(about_data, op_flags = ['readwrite']) as row:\n",
        "    for item in row:\n",
        "      if item[()] ==\"\":  # get value from scalar ndarray of zero dimension           \n",
        "        item[...] = np.nan\n",
        "\n",
        "  about = np.asfarray(about) # convert to float                                        \n",
        "\n",
        "  weights, outof, group = about[0], about[1], about[2]\n",
        "  return weights, outof, group, names;"
      ],
      "metadata": {
        "id": "vbkVHfnDHMtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the data and about data table to create the table 1 output\n",
        "#For each student, print the ID, overall score for each group and overall score\n",
        "#param data is the raw student data (points per assignment)\n",
        "#param about_data is the csv of assignment descriptors\n",
        "def compute_student(data, about_data):\n",
        "  weights, outof, group,headers = split_data(about_data)\n",
        "  #grab number of groups and info matrix filled with 0's\n",
        "  group_num = len(np.unique(group))\n",
        "  info = np.zeros((len(data), group_num))\n",
        "  student_counter = 0\n",
        "  #turn nan to 0's for math assistance\n",
        "  data_nan = np.nan_to_num(data)\n",
        "  #for each student in the list\n",
        "  for student in data_nan:\n",
        "    #assign ID in 0th index\n",
        "    info[student_counter, 0] = student[0]\n",
        "    #for each group hw\n",
        "    for index in range(len(group)):\n",
        "      group_val = group[index]\n",
        "      #if it is not group 0 or a nan, do the summing for the table\n",
        "      if group_val != 0 and not np.isnan(group_val):\n",
        "        info[student_counter, int(group_val)] = info[student_counter, int(group_val)] + (student[index] * weights[index])/outof[index]\n",
        "    #make overall grade column value\n",
        "    for i in range(1, group_num - 1):\n",
        "      info[student_counter, group_num - 1] = info[student_counter, group_num - 1] + info[student_counter, i]\n",
        "    student_counter = student_counter + 1\n",
        "  #print table 1\n",
        "  info = np.around(info, 2)\n",
        "  print_table1(info, group_num)\n",
        "  #print table 2\n",
        "  table2(data, about_data)\n",
        "  #print table 3\n",
        "  table3(info, data)"
      ],
      "metadata": {
        "id": "aflRQH7GNT_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to print table1 so there is not too much code in compute_student\n",
        "#param info is the final info table for the students\n",
        "def print_table1(info, group_num):\n",
        "  print(\"\\n\")\n",
        "  print(\"Table 1:\")\n",
        "  info_T = info.T.astype(str)\n",
        "  #get sizes for printed -- divider\n",
        "  size = len(max(info_T[0], key=len))+6\n",
        "  #print headers for the table, formatted to the size of the greatest element\n",
        "  print(\"+{0:^{1}}|\".format(\"ID\", size-2), end =\"\")\n",
        "  #for each group, print Group #. Modify width for longest value in the list\n",
        "  for i in range(info[1].size - 2):\n",
        "    groupname = \"Group \" + str((i + 1))\n",
        "    print(\"{0:^{1}}|\".format(groupname, len(max(info_T[i+1], key=len))+4), end =\"\")\n",
        "    size = size + len(max(info_T[i+1], key=len))+5\n",
        "  #pritn overall header\n",
        "  print(\"{0:^{1}}+\".format(\"Overall\", len(max(info_T[i+1], key=len))+4))\n",
        "  #print ---- divider\n",
        "  size = size + len(max(info_T[i+1], key=len))+5\n",
        "  print(\"-\"*size)\n",
        "  #for each student, print the data\n",
        "  for row in info:\n",
        "    print(\"+{0:^{1}}|\".format(str(row[0]), len(max(info_T[0], key=len))+4), end =\"\")\n",
        "    for group in range(info[1].size-2):\n",
        "      print(\"{0:^{1}}|\".format(str(row[group+1]), len(max(info_T[group+1], key=len))+4), end =\"\")\n",
        "    print(\"{0:^{1}}+\".format(str(row[group+2]), len(max(info_T[group+1], key=len))+4))\n",
        "  print(\"-\"*size)"
      ],
      "metadata": {
        "id": "M4chsn4y8FKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the data and about data table to create the table 2 output\n",
        "#for each item, print the average, std, max, and min of that class\n",
        "#param data is the raw student data (points per assignment)\n",
        "#param about_data is the csv of assignment descriptors\n",
        "def table2(data, about_data):\n",
        "  weights, outof, group, headers = split_data(about_data)\n",
        "  #get transposition of the data table, results in each column being each \n",
        "  #students value for a HW\n",
        "  data_T = data.T\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"Table 2:\")\n",
        "  print(\"------------------------------------------------------------------------\")\n",
        "  print(\"+ Assignment Name |  Average  |  Standard Dev  |  Maximum  |  Minimum  +\")\n",
        "  print(\"------------------------------------------------------------------------\")\n",
        "  #for each group\n",
        "  for i in range(np.shape(data_T)[0] - 1):\n",
        "    mean = str(round(np.nanmean(data.T[i + 1]),2))\n",
        "    std = str(round(np.nanstd(data.T[i + 1]),2))\n",
        "    max = str(round(np.nanmax(data.T[i + 1]),2))\n",
        "    min = str(round(np.nanmin(data.T[i + 1]),2))\n",
        "    print('+{:^17s}|{:^11s}|{:^16s}|{:^11s}|{:^11s}+'.format(headers[i+1], mean, std, max, min))\n",
        "  print(\"------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "XuD1xMrgG93S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the data and about data table to create the table 3 output\\\n",
        "#collects and prints the correlation coefficient between attendance, last grade, and ID for overall grade\n",
        "#param info is the info table that has the overall grade value\n",
        "#param data is the data table that holds the attendance, ID, and last grade value\n",
        "def table3(info, data):\n",
        "  info_T = info.T\n",
        "  data_T = np.nan_to_num(data).T\n",
        "  #get coef values\n",
        "  attend_coef = np.corrcoef(info_T[-1,:], data_T[1])\n",
        "  lastgrade_coef = np.corrcoef(info_T[-1,:], data_T[2])\n",
        "  id_coef = np.corrcoef(info_T[-1,:], data_T[0])\n",
        "  #round values, get right value to print\n",
        "  attend_coef = np.around(attend_coef, 3)[0,1]\n",
        "  lastgrade_coef = np.around(lastgrade_coef, 3)[0,1]\n",
        "  id_coef = np.around(id_coef, 3)[0,1]\n",
        "  #print values\n",
        "  print(\"\\n\")\n",
        "  print(\"Table 3:\")\n",
        "  print(\"----------------------------------------\")\n",
        "  print(\"Category    |  Pearson Correlation Value\")\n",
        "  print(\"----------------------------------------\")\n",
        "  print(\"Attendance  |  \" + str(attend_coef))\n",
        "  print(\"LastGrade   |  \" + str(lastgrade_coef))\n",
        "  print(\"ID          |  \" + str(id_coef))\n",
        "  print(\"----------------------------------------\")"
      ],
      "metadata": {
        "id": "9A74Ddu2pMBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#completes the extra credit section for performing the drop directive\n",
        "#param data is the raw student data (points per assignment)\n",
        "#param about_data is the csv of assignment descriptors\n",
        "#returns the data array with the dropped value and the table4 array to be printed\n",
        "def drop_directive(data, about_data):\n",
        "  #get array with all rows that have the drop directive\n",
        "  drop = about_data[np.where(about_data[:,0] == \"DROP_ONE_OF\")]\n",
        "  header = about_data[np.where(about_data[:,0] == \"HEADERS\")][0]\n",
        "  #create what will be table4, add empty section for ignored section\n",
        "  dropped = np.copy(data)\n",
        "  dropped = np.concatenate((dropped, np.empty((len(data),len(drop)), dtype=\"U100\")), axis = 1)\n",
        "  #for each possible directive\n",
        "  for directive in drop:\n",
        "    group_to_drop = directive[1]\n",
        "    #grab indexes for the group being dropped\n",
        "    group_index = np.where(about_data[3,:] == group_to_drop)\n",
        "    student_counter = 0\n",
        "    #for each student, find the smallest value among the drop directive group\n",
        "    for student in data:\n",
        "      min = np.infty\n",
        "      min_index = -1\n",
        "      for index in group_index[0]:\n",
        "        if student[index-1] < min:\n",
        "          min = student[index-1]\n",
        "          min_index = index-1\n",
        "      #if min has not changed, must have no assignment in that group\n",
        "      if min == np.infty:\n",
        "        dropped[student_counter, np.size(dropped, 1) - 1] = \"No Assignment in Drop Group\"\n",
        "      #else, set that value to nan and label what was dropped\n",
        "      else:\n",
        "        student[min_index] = np.nan\n",
        "        dropped[student_counter, np.size(dropped, 1) - 1] = \"Item \" + header[min_index+1] + \" was ignored score\" \n",
        "      student_counter = student_counter + 1\n",
        "  return data, dropped"
      ],
      "metadata": {
        "id": "FH_Gofs5zwDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prints the table4 in a neat fashion\n",
        "#param table4 is the table4 data in numpy area fashion\n",
        "def print_table4(table4):\n",
        "  print(\"\\n\")\n",
        "  print(\"Table 4:\")\n",
        "  table4_T = table4.T.astype(str)\n",
        "  for row in table4:\n",
        "    print(\"+{0:^{1}}|\".format(str(row[0]), len(max(table4_T[0], key=len))+4), end =\"\")\n",
        "    for i in range(table4[0].size - 2):\n",
        "      print(\"{0:^{1}}|\".format(str(row[i + 1]), len(max(table4_T[i + 1], key=len))+4), end =\"\")\n",
        "    print(\"{0:^{1}}+\".format(str(row[i + 2]), len(max(table4_T[i + 1], key=len))+4))"
      ],
      "metadata": {
        "id": "yKaez08uEN3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVtAflNDtau"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  #gather file names\n",
        "  DATAFILE = input('Enter the filename that contains the data: ')\n",
        "  ABOUT_DATA = input('Enter the filename that contains the data contexts: ')\n",
        "  #Read in CSV's\n",
        "  data = np.genfromtxt(DATAFILE, delimiter = ',')\n",
        "  about_data = np.genfromtxt(ABOUT_DATA, delimiter = ',',dtype='str')\n",
        "  #UNCOMMENT THE BELOW FOR EC PORTION\n",
        "  #data, table4 = drop_directive(data, about_data)\n",
        "  compute_student(data, about_data)\n",
        "  #UNCOMMENT THE BELOW FOR EC PORTION\n",
        "  #print_table4(table4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGTulz7WAj9a",
        "outputId": "cbb23003-700b-4f6a-e03b-61ed5df552da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the filename that contains the data: data.csv\n",
            "Enter the filename that contains the data contexts: about-data.csv\n",
            "\n",
            "\n",
            "Table 1:\n",
            "+   ID    | Group 1 |Group 2 | Group 3 | Overall +\n",
            "--------------------------------------------------\n",
            "+  100.0  |  35.75  |  17.4  |  36.71  |  89.86  +\n",
            "+  101.0  |  26.69  |  22.5  |  30.06  |  79.25  +\n",
            "+  102.0  |  4.89   |  0.0   |  6.93   |  11.82  +\n",
            "+  103.0  |  20.99  |  11.7  |  14.64  |  47.33  +\n",
            "+  104.0  |  4.74   |  0.0   |  7.66   |  12.41  +\n",
            "+  105.0  |  30.92  |  13.2  |  37.12  |  81.24  +\n",
            "+  106.0  |  25.03  |  15.6  |  21.58  |  62.21  +\n",
            "+  107.0  |  31.84  |  21.3  |  39.48  |  92.62  +\n",
            "+  109.0  |  35.09  |  22.2  |  41.2   |  98.49  +\n",
            "+  110.0  |  30.28  |  12.6  |  11.7   |  54.57  +\n",
            "+  111.0  |  30.99  |  16.2  |  34.94  |  82.13  +\n",
            "+  112.0  |  29.32  |  16.5  |  37.8   |  83.62  +\n",
            "+  113.0  |  25.12  |  16.8  |  31.09  |  73.01  +\n",
            "+  114.0  |  33.11  |  21.0  |  32.6   |  86.72  +\n",
            "+  115.0  |   4.6   |  1.2   |  11.02  |  16.82  +\n",
            "+  116.0  |  30.73  |  18.0  |  31.62  |  80.35  +\n",
            "+  117.0  |  12.91  |  8.4   |  17.78  |  39.09  +\n",
            "+  118.0  |  29.22  |  18.0  |  32.34  |  79.57  +\n",
            "+  119.0  |  33.36  |  19.5  |  33.05  |  85.91  +\n",
            "+  120.0  |  23.31  |  20.4  |  23.58  |  67.29  +\n",
            "+  122.0  |  22.06  |  12.0  |  23.05  |  57.11  +\n",
            "+  123.0  |  7.73   |  3.0   |  10.71  |  21.44  +\n",
            "+  124.0  |  29.6   |  19.5  |  23.72  |  72.82  +\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Table 2:\n",
            "------------------------------------------------------------------------\n",
            "+ Assignment Name |  Average  |  Standard Dev  |  Maximum  |  Minimum  +\n",
            "------------------------------------------------------------------------\n",
            "+   Attendance    |   69.13   |     25.05      |   100.0   |   10.0    +\n",
            "+    LASTGRADE    |   2.39    |      0.96      |    4.0    |    1.0    +\n",
            "+       HW1       |   23.87   |      4.95      |   30.0    |    9.0    +\n",
            "+       HW2       |   20.48   |      6.62      |   27.0    |    0.0    +\n",
            "+       HW3       |   31.75   |      5.94      |   40.0    |   13.0    +\n",
            "+       HW4       |   26.05   |     14.26      |   44.0    |    0.0    +\n",
            "+       HW5       |   29.67   |      5.41      |   38.0    |   16.0    +\n",
            "+       HW6       |   24.79   |      3.16      |   30.0    |   20.0    +\n",
            "+       HW7       |   34.11   |      7.79      |   46.0    |   18.0    +\n",
            "+       HW8       |   26.89   |      4.74      |   30.0    |   16.0    +\n",
            "+      QUIZ1      |   7.18    |      2.47      |   10.0    |    2.0    +\n",
            "+      QUIZ2      |   8.42    |      1.84      |   10.0    |    3.5    +\n",
            "+      QUIZ3      |   6.16    |      2.29      |   10.0    |    2.0    +\n",
            "+      QUIZ4      |   6.92    |      2.18      |    9.0    |    3.5    +\n",
            "+     MIDTERM     |   55.89   |     16.41      |   86.0    |   23.5    +\n",
            "+      FINAL      |   61.62   |     24.54      |   89.0    |    0.0    +\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Table 3:\n",
            "----------------------------------------\n",
            "Category    |  Pearson Correlation Value\n",
            "----------------------------------------\n",
            "Attendance  |  0.982\n",
            "LastGrade   |  0.765\n",
            "ID          |  -0.012\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}